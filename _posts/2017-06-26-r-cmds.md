---
layout: post
title: Useful R commands/Tips
tags: [R]
categories: notes
---
* R is indexed 1.
* **read.csv**()
* **summary**()
    * also used to see the # of NA's
* **str**()
* **table**() 
    * when 2 args are used, first will be listed on the left, second on top
* **nrow**() to get the number oftraining examples
* **hist**()
* **boxplot**(oneFeature ~ anotherFeature)
* **sort**(table)
* Top2 = **subset**(mvt, LocationDescription=="ALLEY" \| LocationDescription=="GAS STATION")) OR
    * Top5 = subset(mvt, LocationDescription **%in%** c("STREET", "ALLEY"))
* **factor**() to get rid of unnecessary factors
* **plot** (x,y) 
    * **type="l"** to get smooth graph
    * **col** = "red"
    * **colors()** to get all possible values for argument 'col'
    * lty=2 to get different type of line
* lines() to add line to existing graph
* abline(v=as.Date(c(someDate)), lwd=someNum) to pinpoint on existing Graph
    * lwd is for line thickness
* tapply(1stArg, 2ndArg, function) sort by 2ndArg, then apply function on 1stArg
    * Ex:
    sort(tapply(CPS$Education == "No high school diploma", CPS$MetroArea, mean, na.rm=TRUE)) will return proportion of interviewees from each metropolitan area who have not received a high school diploma, ignoring missing values
* **ctrl+L** to clear console
* is.na(column)
* mean(c(TRUE,TRUE,TRUE,FALSe)) gives 0.75
* Convert code to values by connecting 2 dataframes
    *Ex: combined = merge(CPS,MetroAreaMap, by.x="MetroAreaCode",by.y="Code",all.x=TRUE). Last arg is to keep all rows from CPS as NAs even if there is no match.
* **jitter()** 
    * adds or subtracts a small amount of random noise to the values passed to it, and two runs will yield different results correct
* **lm**(thingToPredict ~ IndependentVar1 + IndependentVar2, data=source)
    * use **.** in place of the Independent Variables to take them all
    * **residuals** to get the difference vector between lm and actual
    * **predict**(modelName, testSet)
    * **step**(linearRegModel) is a function that automates the procedure of trying different combo of variables to find a good compromise of model simplicity (num of independent variables and the quality of the model: R<sup>2</sup>)
* **cor**(variable1, variable) to calculate the correlation between two variables
    * cor(dataset) to see correlation between any two variables of the dataset
* na.omit(dataset)
* factor --- the same as OneHotEncoding in Python
    * choose most popular factor to be the reference, then create a feature for each of the other factors
    * As an example, consider the unordered factor variable "color", with levels "red", "green", and "blue". If "green" were the reference level, then we would add binary variables "colorred" and "colorblue" to a linear regression problem. All red examples would have colorred=1 and colorblue=0. All blue examples would have colorred=0 and colorblue=1. All green examples would have colorred=0 and colorblue=0.
    * R automatically sets the reference level to be the first alphabetically => to reset level use **reset**(data$variable, factorToBeTheReference)

