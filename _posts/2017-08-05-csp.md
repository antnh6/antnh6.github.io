---
layout: post
title: Constraint Satisfaction Problems (CSPs)
tags: [AI, reinforcement-learning]
categories: notes
use-math: true
--- 


- [Overview](#0)
- [How to solve CSPs](#2)
    - [Filtering](#filtering)
    - [Ordering](#ordering)
    - [Structure](#structure)
<a id='0'></a>

- [Another way to solve CSPs: Iterative Improvement](#another-way-to-solve-csps-iterative-improvement)


<a id='0'></a>
# Overview

CSPs are a special type of Search Problems because they have their very own specific structure:
- Variables (similar to States)
- Domain (the values that these variables can take on)
- Constraints thats say which assignments to the variables are legal (goal test)
    
Therefore, we can use special purpose algorithms beyond generic search algorithms to solve them. 

The goal for now <a id='2'></a>is to find a solution or to find out that there is no solutions in reasonable time, although we could tweak the algorithms to find all solutions or define a cost function to find the best solution later on.


<a id='2'></a>  
# How to solve CSPs
- **BFS** takes a long time because the goal test is only done at leaf level.
- **DFS** takes less time to arrive at leaf level but might make mistakes too early on without realizing

One solution: 
**Backtracking** = DFS with 2 improvements **one variable at a time** and **checking constraints as we go**
<p align="center">
    <img src="../../img/post-img/reinforcement/search/csp/1.png" height="80%" width="80%">
</p>

Three add-ons to make Backtracking run faster:
### Filtering
is this notion of ruling out elements in the domain of variables that do not have assignment yet
1. **Forward checking** For each variable,
    - Assign a domain value to the variable
    - Add all nodes that point to the variable
    - Enforce **arc consistency**. An arc X->Y is consistent iff for any value that X can take on, there is at least one value for Y that does not break any constraints. To make an arc consistent, remove from the tail any value that makes the arc inconsistent.
2. **Arc consistency** is almost the same as forward checking, except that we would also repeat step 2 for every node added in step 2, i.e. we would propagate arc consistency across all arcs.  

Generalizing that to **k-consistency** which is this concept which says that for each k nodes, any consistent assignment to k-1 can be extended to the $$k^{th}$$ node $$\rightarrow$$ 2-consistency = arc consistency; 3-consistency = path consistency.

### Ordering
- **Minimum remaining values (MRV)** chooses the variable with the smallest domain next. The reasoning is that this variable is near failure, so by trying it first, we would have fewer variables to back track on in case it fails.
- **Least constraining values (LCV)** chooses the value that does not cross off too many neighboring values.

### Structure
The idea is to make a graph more like a tree by using cutset conditioning by "deleting" a few nodes, i.e. pretending that these nodes have taken on some fixed value so that the rest of the nodes looks like a tree.

Why might we prefer tree-structured CSPs? Answer: they can be solved faster. If a graph is tree structured (i.e. has no loops) then the CSP can be solved in O($$n*d^2$$) time as compared to general CSPs, where worst-case time is O($$d^n$$).Because for tree-structured CSPs we can choose an ordering such that every nodeâ€™s parent precedes it in the ordering, and enforce arc consistency from the leaf level up. Then we can greedily assign the nodes in order, starting from the root, and will find a consistent assignment **without backtracking**.



# Another way to solve CSPs: Iterative Improvement

Start with a complete assignment, pick conflicted variables at random then reassign those variables to values that result in min conflicts => This works out in good cases with high probability and is effective in practice although incomplete 

Local search: min conflicts????

Simulated Annealing to escape local max

