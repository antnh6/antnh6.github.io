---
layout: post
title: Convolutional Neural Networks (CNN)
tags: [supervised, machine-learning]
categories: notes
---
Like most things, Multilayer Perceptron (MLP) has its own set of limitations.
- Since it's **fully connected**, the parameters (aka weights) can blow up really fast, so can the computational complexity.
- It takes inputs as vector, so if any 2D input say an image grid must be converted to a vector before MLP can take it up. However, the knowledge of where the pixels are located in reference to one another are "lost in translation". 

This is where CNN (Convolutional) comes in to save the day because 
- Not all inputs are connected to every unit in the next layer.
- It takes in matrices as input.

To construct a CNN:
- Create a sliding window
- Blue matrix = convolutional layer
- Weights from nodes of the same window can be represented in a grid form for calculation convenience.

<p align="center">
  <img src="../../img/post-img/nn/cnn/2.png" height="80%" width="80%">
</p>

<p align="center">
  <img src="../../img/post-img/nn/cnn/3.png" height="80%" width="80%">
</p>

- Visualizing the learned filter will tell us the patterns the filter is designed to detect.
- Run process with many different filters

Filters that function as edge detector are very imp

3D images are seen as 3d array with the depth array seen as 3 arrays R, G, B
Filters are now 3D, a stack of 3 2D arrays

You would then get a convolutional layer, a stack of 2D feature(activation) maps, each of which comes from a filter.
<p align="center">
  <img src="../../img/post-img/nn/cnn/4.png" height="80%" width="80%">
</p>

This layer can then be viewed as the original grid, and filtered in the same manner.

By specifying a **loss function**, we can implicitly tell CNNs what patterns the filters should look for.

To increase number of nodes in Convolution Layer = Increase number of filters

### Stride and Padding

**Stride** = the amount by which a filter slides over an image, i.e. the number of pixels over at a time
This could result in the sliding filter going out of the image boundaries. 
<p align="center">
  <img src="../../img/post-img/nn/cnn/5.png" height="80%" width="80%">
</p>
To circumvent this, we could apply **padding** in which we pad the image with some values beforehand. Or we could simply forgo the nodes in the convolutional layer where this happens (this approach will result in loss of information about the original image though). 

The number of **parameters** in a convolutional layer (CL) is
> filterDim1 * filterDim2 * DepthOfPreviousLayer * NumFilters + NumFilters(Biases)

The **shape** of a CL is
* with padding:
\\[height = ceil(\frac{heightOfPreviousLayer}{Stride})\\]
\\[width = ceil(\frac{widthOfPreviousLayer}{Stride})\\]
* without padding:
\\[height = ceil(\frac{heightOfPreviousLayer - heightOfFilter + 1}{Stride})\\]
\\[width = ceil(\frac{widthOfPreviousLayer - widthOfFilter + 1}{Stride})\\]

The **depth** of a CL is always equal to NumOfFilters

### Pooling Techniques
usually done following a CL
- **Max Pooling** Layer: 
  - need stride and kernel_size to get the max in each section of feature map
  - only reduce dimensionality 
- **Global Average**: 
  - for each feature map, get the average
  - reduce stack of arrays down to a vector
- and many more

### CNN architecture
<p align="center">
  <img src="../../img/post-img/nn/cnn/7.png" height="20%" width="20%">
</p>
After alternating between convoluting and pooling, we will get a much deeper matrix in which each layer filters for one thing, which we can then flatten and feed into a deep NN.

### Random

To train NNs faster, use a GPU-enabled virtual server from AWS