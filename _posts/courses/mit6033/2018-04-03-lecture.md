---
layout: post
title: Lecture 4 
<!--image: /img/avatar-icon.png-->
categories: courses/mit6033
tags: [testfile]
---

# Lecture 4 

from this video [series](https://www.youtube.com/watch?v=zm2VP0kHl1M&list=PL6535748F59DCA484)

- Recitations, Lectures, Tutorials

microprocessor = mini processor
connecting many modules to form a software
soft modularity
modules = object files = parts of a software
library = collection of object files with an index portion at the top to tell what's where
- symbol resolution = symbols are defined in each object file, needs to resolve them and put them together in 1 file (D = set of defined symbols, U = set of undefined symbols, O = set of all symbols)
- relocation 
are colletively called linking (links all object files into a program which a loader can load into memory then run)
relocatable and shared object files (pointers to commonly used functions so as to avoid too much texts) 
library libc contains all the c functions, e.g. printf
library math contains all the math functions, e.g. sqr 
so put libraries at the end of the compilation

static linking (copy all object files into one big file at compile time) vs. dynamic linking (keep a reference for that function to object file, so refs areonly invoked at runtime => positions have to be object-independent)

------------------------------------------------------------------------------

# Lecture 5 

client/server

"Stack discipline" between caller and callee functions 
- Callee crashes => Caller also crashes
- Callee corrupts stack 

Solution 1: client/service each on a computer
- Cons: not knowing if service is really slow or it's not returning
=> client uses a timer

*Trusted Intermediary* is the idea that many clients can use the same service, but they need not trust each other or know about each other's existence.

Implementation:

- Remote Procedure Call (RPC)
    - Sun RPC
    - XML RPC (newer)
- RPC is not the same as Procedure Call in that 
    - No fate sharing between client and service
    - Hard to tell between failure and extremely slow service. Three sematics:
        - exactly once
        - at least once requires the need for *idem-potent* 
        - at most once

A *handler* lets the service notify the client that it has completed the requested procedure call (which call specifically)
*Intermediary* for client/service organization is a little different because it acts as a buffer for requests to livei in, thus eliminates the need for the client and service to be up and running at the same time.

---------------------------------------------------------------------------------------

# Virtual Processors (Lecture 7)

Each program runs on one virtual processor, aka thread (a state of a program)
*Cooperative scheduling* vs. preemptive scheduling
threads running in same address space vs. threads running in different address space

switching stacks
Stack pointer is pointing to stacks. 

- After switching from stack for thread 1, pop the latest thing which is a return address and continue execution for that thread there. 
- Before calling yield, save address of where to continue execution on the stack of that thread.

Because no module should have the ability to interfere with the execution of another module i.e. hogging the processor by not calling yield (enforcced modularity), preemptive is a step-up from cooperative scheduling.

timer interrupt causes the processor to execute a special piece of code in kernel to call yield on behalf of running thread.

Now, running threads in different address spaces.
A process is made up of many threads. A processs runs in an address space.

microprocessor vs. processor???

Layer of threads

microprocessor stems out to main and interrupt and ea process has many diff threads (may use cooperative here).

kernel is in charge of switching user programs.

------------------------------------------------------------------------------

# Lecture 8 

3 components aka modules of a Web server system
- networking module
- web server html module
- disk module

Performance

- **pipelining** messes with the seemingly inverse relationship between **throughput**(how many done per unit time) and **latency**(how long it takes to get one done).
- io bottleneck: throughput of whole system = throughput of bottleneck (or slowest stage)

Concurrency within a module = have more threads/mini modules for that module so those threads can work concurrently

------------------------------------------

# Lecture 9: Intro to Networking

router = a switch that has many options stemming out from

(Last Updated: June 9, 2018)