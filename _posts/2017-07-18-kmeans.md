---
layout: post
title: k-Means
tags: [unsupervised, clustering]
categories: notes
---

### Choosing Optimal k for kMeans
While dendrograms can be used to select the final number of clusters for Hierarchical Clustering, we can't use dendrograms for k-means clustering => use a **scree plot**, which works for any clustering algorithm.

A standard scree plot has the number of clusters on the x-axis, and the sum of the within-cluster sum of squares on the y-axis. The within-cluster sum of squares for a cluster is the sum, across all points in the cluster, of the squared distance between each point and the centroid of the cluster.  We ideally want very small within-cluster sum of squares, since this means that the points are all very close to their centroid. 

<p align="center">
  <img src="../../img/post-img/unsupervised/clustering/2.png" height="80%" width="80%">
</p>

To determine the best number of clusters using this plot, we want to look for a bend, or elbow, in the plot. This means that we want to find the number of clusters for which increasing the number of clusters further does not significantly help to reduce the within-cluster sum of squares. For this particular dataset, it looks like 4 or 5 clusters is a good choice. Beyond 5, increasing the number of clusters does not really reduce the within-cluster sum of squares too much [(source)][1].


[1]: https://courses.edx.org/courses/course-v1:MITx+15.071x+2T2017/courseware/d32b0c36ff484c228b8117257349d0e6/312aa7d9e6f9438397c13b1cfb3ea76b/?child=first


